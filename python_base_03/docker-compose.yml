version: "3.9"

secrets:
  mongodb_service_name:
    file: ./secrets/mongodb_service_name
  mongodb_root_user:
    file: ./secrets/mongodb_root_user
  mongodb_root_password:
    file: ./secrets/mongodb_root_password
  mongodb_user:
    file: ./secrets/mongodb_user
  mongodb_user_password:
    file: ./secrets/mongodb_user_password
  mongodb_db_name:
    file: ./secrets/mongodb_db_name
  mongodb_port:
    file: ./secrets/mongodb_port
  redis_service_name:
    file: ./secrets/redis_service_name
  redis_host:
    file: ./secrets/redis_host
  redis_port:
    file: ./secrets/redis_port
  flask_service_name:
    file: ./secrets/flask_service_name
  flask_port:
    file: ./secrets/flask_port
  pythonpath:
    file: ./secrets/pythonpath
  app_secret_key:
    file: ./secrets/app_secret_key
  jwt_secret_key:
    file: ./secrets/jwt_secret_key
  encryption_key:
    file: ./secrets/encryption_key
  redis_password:
    file: ./secrets/redis_password
  stripe_secret_key:
    file: ./secrets/stripe_secret_key
  grafana_admin_password:
    file: ./secrets/grafana_admin_password
  vault_token:
    file: ./secrets/vault_token

services:
  k8s-init:
    image: alpine:3.18
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - .:/workspace
      - k8s-config:/k8s-config
    environment:
      - VAULT_ADDR=http://vault:8200
      - KUBECONFIG=/k8s-config/kubeconfig
    command: >
      sh -c "
        echo 'ðŸ”„ Phase 1: System initialization (with internet access)' &&
        apk add --no-cache docker-cli curl kind kubectl &&
        cd /workspace &&
        kind create cluster --config kind-config.yaml --kubeconfig /k8s-config/kubeconfig &&
        until kubectl --kubeconfig /k8s-config/kubeconfig get pods -A | grep -q 'Running'; do
          echo 'Waiting for cluster to be ready...'
          sleep 5
        done &&
        echo 'âœ… Kubernetes cluster is ready' &&
        echo 'ðŸ”’ Setup complete - container will exit'
      "
    networks:
      vault_internal:
        aliases:
          - k8s-init
      init_network: {}  # Temporary network for initialization
    restart: "no"  # Only run once
    healthcheck:
      test: ["CMD", "kubectl", "--kubeconfig", "/k8s-config/kubeconfig", "get", "pods", "-A"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

  vault:
    image: hashicorp/vault:1.15
    cap_add:
      - IPC_LOCK
    environment:
      VAULT_ADDR: 'http://0.0.0.0:8200'
      VAULT_API_ADDR: 'http://0.0.0.0:8200'
      VAULT_DEV_ROOT_TOKEN_ID: 'dev-token'
      VAULT_DEV_LISTEN_ADDRESS: '0.0.0.0:8200'
    command: server -dev
    networks:
      vault_internal:
        aliases:
          - vault
      init_network:
        aliases:
          - vault
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 10s
      timeout: 5s
      retries: 3
    volumes:
      - vault-data:/vault/file
      - k8s-config:/k8s-config:ro
    depends_on:
      - k8s-init

  vault-config:
    image: hashicorp/vault:1.15
    volumes:
      - k8s-config:/k8s-config:ro
      - ${PWD}/secrets:/secrets
      - ${PWD}/scripts:/scripts
    environment:
      - VAULT_ADDR=http://vault:8200
      - VAULT_TOKEN=dev-token
      - KUBECONFIG=/k8s-config/kubeconfig
    command: >
      sh -c "
        apk add --no-cache curl &&
        mkdir -p /secrets &&
        if [ ! -f /secrets/vault_token ]; then
          echo 'Creating vault_token file...' &&
          echo 'dev-token' > /secrets/vault_token &&
          chmod 600 /secrets/vault_token &&
          echo 'âœ… Vault token secret has been configured!'
        fi &&
        echo 'ðŸ”’ Making scripts temporarily executable...' &&
        chmod +x /scripts/*.sh &&
        echo 'ðŸš€ Running initialization scripts...' &&
        /scripts/init-vault-secrets.sh &&
        echo 'ðŸ”’ Removing execute permissions from scripts...' &&
        chmod -x /scripts/*.sh &&
        echo 'âœ… Vault configuration completed! Scripts are now locked.'
      "
    networks:
      - vault_internal
      - init_network
    depends_on:
      vault:
        condition: service_healthy
    restart: "no"

  flask_app:
    build:
      context: .
      dockerfile: Dockerfile
    image: silvella/cr_credit_system_flask_app:latest
    container_name: flask
    environment:
      - FLASK_ENV=development
      - VAULT_ADDR=http://vault:8200
      - VAULT_TOKEN=dev-token
      - KUBECONFIG=/k8s-config/kubeconfig
      - PYTHONPATH_FILE=/run/secrets/pythonpath
      - MONGODB_SERVICE_NAME_FILE=/run/secrets/mongodb_service_name
      - MONGODB_ROOT_USER_FILE=/run/secrets/mongodb_root_user
      - MONGODB_ROOT_PASSWORD_FILE=/run/secrets/mongodb_root_password
      - MONGODB_DB_NAME_FILE=/run/secrets/mongodb_db_name
      - REDIS_SERVICE_NAME_FILE=/run/secrets/redis_service_name
      - REDIS_HOST_FILE=/run/secrets/redis_host
      - REDIS_PORT_FILE=/run/secrets/redis_port
      - FLASK_SERVICE_NAME_FILE=/run/secrets/flask_service_name
      - FLASK_PORT_FILE=/run/secrets/flask_port
      - APP_SECRET_KEY_FILE=/run/secrets/app_secret_key
      - JWT_SECRET_KEY_FILE=/run/secrets/jwt_secret_key
      - ENCRYPTION_KEY_FILE=/run/secrets/encryption_key
      - REDIS_PASSWORD_FILE=/run/secrets/redis_password
      - STRIPE_SECRET_KEY_FILE=/run/secrets/stripe_secret_key
    ports:
      - "5000:5000"
    volumes:
      - ./plugins:/app/plugins
      - ./core:/app/core
      - ./static:/app/static
      - ./tools:/app/tools
      - ./utils:/app/utils
      - k8s-config:/k8s-config:ro
    secrets:
      - mongodb_service_name
      - mongodb_root_user
      - mongodb_root_password
      - mongodb_db_name
      - redis_service_name
      - redis_host
      - redis_port
      - flask_service_name
      - flask_port
      - pythonpath
      - app_secret_key
      - jwt_secret_key
      - encryption_key
      - redis_password
      - stripe_secret_key
      - vault_token
    depends_on:
      vault-config:
        condition: service_completed_successfully
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - vault_internal
      - cr_credit_system_network
    command: >
      sh -c "
      pip install --no-cache-dir -r /app/requirements.txt &&
      pip install --no-cache-dir gevent &&
      gunicorn -b 0.0.0.0:5000 --worker-class gevent app:app
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 10s
      retries: 5
      start_period: 10s

  mongodb:
    image: mongo:latest
    container_name: mongodb
    restart: always
    command: ["mongod", "--bind_ip_all"]
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: rootpassword
      MONGO_INITDB_DATABASE: admin
    volumes:
      - cr_credit_system_mongodb_data:/data/db
      - ./secrets:/run/secrets:ro
    secrets:
      - mongodb_root_user
      - mongodb_root_password
      - mongodb_db_name
    ports:
      - "27017:27017"
    networks:
      - cr_credit_system_network
    healthcheck:
      test: ["CMD", "mongosh", "--port", "27017", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  redis:
    image: redis:alpine
    container_name: redis
    restart: always
    command: sh -c 'redis-server --requirepass "$$(cat /run/secrets/redis_password)"'
    volumes:
      - cr_credit_system_redis_data:/data
      - ./secrets:/run/secrets:ro
    secrets:
      - redis_password
      - redis_service_name
      - redis_host
      - redis_port
    ports:
      - "6379:6379"
    networks:
      - cr_credit_system_network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "$$(cat /run/secrets/redis_password)", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  nginx:
    image: nginx:latest
    container_name: cr_credit_system_nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "8080:80"
    depends_on:
      - flask_app
    networks:
      - cr_credit_system_network

  prometheus:
    image: prom/prometheus:latest
    container_name: cr_credit_system_prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - cr_credit_system_network
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  grafana:
    image: grafana/grafana:latest
    container_name: cr_credit_system_grafana
    restart: always
    environment:
      - GF_SECURITY_ADMIN_PASSWORD_FILE=/run/secrets/grafana_admin_password
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./secrets:/run/secrets:ro
    secrets:
      - grafana_admin_password
    ports:
      - "3000:3000"
    networks:
      - cr_credit_system_network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  alertmanager:
    image: prom/alertmanager:latest
    container_name: cr_credit_system_alertmanager
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager
    ports:
      - "9093:9093"
    networks:
      - cr_credit_system_network
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  vault_internal:
    name: cr_credit_system_vault_internal
    driver: bridge
    internal: true
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
      com.docker.network.bridge.enable_ip_masquerade: "false"
    ipam:
      driver: default
      config:
        - subnet: "172.28.0.0/16"
          ip_range: "172.28.5.0/24"
          gateway: "172.28.0.1"
    enable_ipv6: false
  init_network:
    name: cr_credit_system_init_network
    driver: bridge
    internal: false  # Needs internet access for initialization
  cr_credit_system_network:
    name: cr_credit_system_network
    driver: bridge

volumes:
  app_secrets:
    driver: local
  cr_credit_system_redis_data:
    name: cr_credit_system_redis_data
  cr_credit_system_mongodb_data:
    name: cr_credit_system_mongodb_data
  prometheus_data:
    name: cr_credit_system_prometheus_data
  grafana_data:
    name: cr_credit_system_grafana_data
  alertmanager_data:
    name: cr_credit_system_alertmanager_data
  k8s-config:
    name: cr_credit_system_k8s_config
  vault-data:
    name: cr_credit_system_vault_data
